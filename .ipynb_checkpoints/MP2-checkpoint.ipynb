{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5MNsWoMEV_o"
   },
   "source": [
    "MP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceohaL_jEi4B"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwPk8xvSK8gq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YCiAM6QEh36"
   },
   "source": [
    "# Loading and splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKxl0ikhE0mQ"
   },
   "source": [
    "We use a 80/20 split for the training and testing data which can be seen by the choices of the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrg6ol3_LKI_"
   },
   "outputs": [],
   "source": [
    "  ratings = pd.read_csv(\"http://www.cs.toronto.edu/~guerzhoy/324/movielens/ratings.csv\")\n",
    "  ratings_train = ratings.sort_values(by=['timestamp'])[0:80668]\n",
    "  ratings_test = ratings.sort_values(by=['timestamp'])[80668:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "h1F4_cAkFDXQ",
    "outputId": "ce062974-8eed-48a3-f724-ea0fdd4c3bf9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9550805d-645a-4c70-b9db-be4cdfc02abc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66719</th>\n",
       "      <td>429</td>\n",
       "      <td>595</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>429</td>\n",
       "      <td>588</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66717</th>\n",
       "      <td>429</td>\n",
       "      <td>590</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66718</th>\n",
       "      <td>429</td>\n",
       "      <td>592</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66712</th>\n",
       "      <td>429</td>\n",
       "      <td>432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79752</th>\n",
       "      <td>495</td>\n",
       "      <td>132796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1458634739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79756</th>\n",
       "      <td>495</td>\n",
       "      <td>139385</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1458634761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79747</th>\n",
       "      <td>495</td>\n",
       "      <td>122882</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1458634764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79566</th>\n",
       "      <td>495</td>\n",
       "      <td>2959</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1458634866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>495</td>\n",
       "      <td>99114</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1458635162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80668 rows Ã— 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9550805d-645a-4c70-b9db-be4cdfc02abc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9550805d-645a-4c70-b9db-be4cdfc02abc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9550805d-645a-4c70-b9db-be4cdfc02abc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "66719     429      595     5.0   828124615\n",
       "66716     429      588     5.0   828124615\n",
       "66717     429      590     5.0   828124615\n",
       "66718     429      592     5.0   828124615\n",
       "66712     429      432     3.0   828124615\n",
       "...       ...      ...     ...         ...\n",
       "79752     495   132796     1.0  1458634739\n",
       "79756     495   139385     5.0  1458634761\n",
       "79747     495   122882     4.5  1458634764\n",
       "79566     495     2959     5.0  1458634866\n",
       "79724     495    99114     5.0  1458635162\n",
       "\n",
       "[80668 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfUIBUOiFK8b"
   },
   "source": [
    "# Part 1: Training with **Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94KtfZfhKtwv"
   },
   "source": [
    "We choose to go for one embedding object here for users and movies instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ja8ac4w6L0Cg"
   },
   "outputs": [],
   "source": [
    "n_users = len(ratings_train.userId.unique())\n",
    "n_movies = len(ratings_train.movieId.unique())\n",
    "n = n_users + n_movies\n",
    "d = 10\n",
    "device = 'cuda'\n",
    "embedding = torch.nn.Embedding(n, d).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icevuLRHFfrP"
   },
   "source": [
    "## Mapping the Movies and Users to Indicies forward and backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULnlW5kKK4zD"
   },
   "source": [
    "Here we want to access the movies and users as indicies, but then also access the incidices to get the movies and users. This will become very useful for training the data, and also very useful for getting the correct userIDs and movieIDs at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oBA8hoyd3_-"
   },
   "outputs": [],
   "source": [
    "map_movies = {}\n",
    "map_users = {}\n",
    "map_idx_user = {}\n",
    "map_idx_movie = {}\n",
    "\n",
    "i = 0\n",
    "for index in ratings_train.index:\n",
    "  if ratings_train[\"movieId\"][index] not in map_movies:\n",
    "    map_movies[ratings_train[\"movieId\"][index]] = i\n",
    "    map_idx_movie[i] = ratings_train[\"movieId\"][index]\n",
    "    i+=1\n",
    "\n",
    "i = 0\n",
    "for index in ratings_train.index:\n",
    "  if ratings_train[\"userId\"][index] not in map_users:\n",
    "    map_users[ratings_train[\"userId\"][index]] = i\n",
    "    map_idx_user[i] = ratings_train[\"userId\"][index]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuHCHpbsFv1t"
   },
   "source": [
    "## Creating the Adjacency Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz89ZbzjLKL1"
   },
   "source": [
    "The adjacency matrix represents where the user rated a movie 5 star as 1, has seen the movie but not rated it 5 star as -1, and not seen as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAqS3tAq-a1z"
   },
   "outputs": [],
   "source": [
    "A = torch.zeros((n_users, n_movies))\n",
    "for index in ratings_train.index:\n",
    "  if ratings_train[\"rating\"][index] == 5.0:\n",
    "    A[map_users[ratings_train[\"userId\"][index]]][map_movies[ratings_train[\"movieId\"][index]]] = 1\n",
    "  else:\n",
    "    A[map_users[ratings_train[\"userId\"][index]]][map_movies[ratings_train[\"movieId\"][index]]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvAg7uzDF_ov",
    "outputId": "e49ef5f5-3824-48eb-e314-3c75e230892c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0., -1.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ..., -1., -1.,  1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRYnXA91GCn8"
   },
   "source": [
    "## Creating the Embeddings for the Movies and Users as an update function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNZEzKQrLX5H"
   },
   "source": [
    "Every time the training loop runs, the new embeddings of the users and movies need to be updated. This function will do that in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5M2EqHttRRi"
   },
   "outputs": [],
   "source": [
    "def update(n_users, n_movies, embedding):\n",
    "  emb_movies = embedding(torch.arange(n_movies).to(device))\n",
    "\n",
    "  emb_users = embedding(torch.arange(n_movies, n).to(device))\n",
    "\n",
    "  return emb_users, emb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYlYoWv1GMTo"
   },
   "source": [
    "## The Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJFAmiTFL15N"
   },
   "source": [
    "The cost function is as described in the lab handout. The difference here is that it returns 1/total, since we need to optimize the function given in the handout, we try to reduce 1/total as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qTXut-Dy55E"
   },
   "outputs": [],
   "source": [
    "def cost(n_users, n_movies, emb_users, emb_movies, A):\n",
    "    total = 0 \n",
    "    for i in range(len(A)):\n",
    "      movies_5star = np.where(A[i] == 1)[0]\n",
    "      movies_4star = np.where(A[i] != 1)[0]\n",
    "\n",
    "      five_star_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[i],torch.transpose(emb_movies[movies_5star], 0, 1))))) * 200\n",
    "      four_star_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[i],torch.transpose(emb_movies[movies_4star], 0, 1)))))\n",
    "\n",
    "      total+= (five_star_sum - four_star_sum)\n",
    "\n",
    "    \n",
    "    return 1/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zKwPnTGIOwB"
   },
   "source": [
    "## Training the Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3Wt7MiLME9X"
   },
   "source": [
    "The training loop takes 1000 epochs, a learning rate of 0.0001, and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJThbEp_Qre1",
    "outputId": "149b4efa-35e9-4fea-95ad-72c0a355504b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0 loss= tensor(3.5780e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  50 loss= tensor(3.5775e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  100 loss= tensor(3.5769e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  150 loss= tensor(3.5764e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  200 loss= tensor(3.5759e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  250 loss= tensor(3.5753e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  300 loss= tensor(3.5748e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  350 loss= tensor(3.5743e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  400 loss= tensor(3.5737e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  450 loss= tensor(3.5732e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  500 loss= tensor(3.5727e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  550 loss= tensor(3.5721e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  600 loss= tensor(3.5716e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  650 loss= tensor(3.5710e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  700 loss= tensor(3.5705e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  750 loss= tensor(3.5700e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  800 loss= tensor(3.5694e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  850 loss= tensor(3.5689e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  900 loss= tensor(3.5684e-07, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "epoch =  950 loss= tensor(3.5678e-07, device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 0.0001\n",
    "\n",
    "params = [*embedding.parameters()] \n",
    "optimizer = torch.optim.Adam(params, lr = lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    emb_users, emb_movies = update(n_users, n_movies, embedding)\n",
    "    loss = cost(n_users, n_movies, emb_users, emb_movies, A)\n",
    "\n",
    "    optimizer.zero_grad()           # cleans the gradients\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "  \n",
    "    if epoch % 50 == 0:\n",
    "      print(\"epoch = \", epoch, \"loss=\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GZXsD6_IU3K"
   },
   "source": [
    "## Getting 150 highest dot products between movies and users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THu4hD5mIehX"
   },
   "source": [
    "Here we find the top150 movies per user. I do think this code is the hardest to follow along, so it is commented to explain each line, instead of an overview.\n",
    "\n",
    "Important to note the \"torch.where(A[users] == 0)\" which states that the dot products are occuring between users and movies that have NOT been seen already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "j4BQqnh4eTuf",
    "outputId": "a71a7ba3-6950-4c68-fb5a-fd5c2af3358d"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ba1cb241c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# These statements check if there are 150 reccomendations for the movies or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0msorted_movie_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindicies_sorted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0mtop_150\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_movie_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtake_top\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "all_comb = torch.matmul(emb_users, torch.transpose(emb_movies, 0 , 1))\n",
    "# Multiplies the user and movies embeddings matricies together\n",
    "\n",
    "all_recall = []\n",
    "\n",
    "for users in range(n_users):\n",
    "  ind = torch.where(A[users] == 0)[0] \n",
    "  # Indicies for the movies that the user has not seen\n",
    "\n",
    "  user_mul_movie = all_comb[users, ind]\n",
    "  # Gets the dot product values of all the movies that have not been seen for the user \n",
    "\n",
    "  indicies_sorted = torch.argsort(user_mul_movie,-1,True)\n",
    "  # Sorts these dot products\n",
    "\n",
    "  if len(indicies_sorted) < 150:\n",
    "    take_top = len(indicies_sorted)\n",
    "  else:\n",
    "    take_top = 150\n",
    "  # These statements check if there are 150 reccomendations for the movies or less\n",
    "\n",
    "  sorted_movie_ids = ind[indicies_sorted]\n",
    "  top_150 = sorted_movie_ids[0:take_top]\n",
    "\n",
    "  all_recall.append(top_150)\n",
    "  # Puts the top movie reccomendations in a list where the indicies represent the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLc-_MI2_rEj"
   },
   "outputs": [],
   "source": [
    "all_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jMP6eVcI2GD"
   },
   "source": [
    "## Dropping Test set rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jIVPx96I5k_"
   },
   "source": [
    "All rows that are dropped are the ones where the user or movie do not occur in the training data. These cannot possibly be in the Recall150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY2KkwaJmu0A"
   },
   "outputs": [],
   "source": [
    "for index in ratings_test.index:\n",
    "  if (ratings_test[\"userId\"][index] not in map_users) or (ratings_test[\"movieId\"][index] not in map_movies):\n",
    "    ratings_test = ratings_test.drop(index = index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZo6MLKz0RjH"
   },
   "outputs": [],
   "source": [
    "ratings_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMInDyQXJHcz"
   },
   "source": [
    "## Creating a Test set adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7boGehabOaw1"
   },
   "source": [
    "This creates the adjacency matrix for the test data. Same procedure as the training adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndYNZRnNpYTf"
   },
   "outputs": [],
   "source": [
    "A_test = torch.zeros((n_users, n_movies))\n",
    "for (i, index) in enumerate(ratings_test.index):\n",
    "  if ratings_test[\"rating\"][index] == 5:\n",
    "    A_test[map_users[ratings_test[\"userId\"][index]]][map_movies[ratings_test[\"movieId\"][index]]] = 1\n",
    "  else:\n",
    "    A_test[map_users[ratings_test[\"userId\"][index]]][map_movies[ratings_test[\"movieId\"][index]]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdFdcyIgAkMY"
   },
   "outputs": [],
   "source": [
    "A_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFhShLeLJPqo"
   },
   "source": [
    "## Implimenting @Recall150 (Test Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCQAS0CvJTt9"
   },
   "source": [
    "The output is a dictionary containing the user as the key and a tuple (R_u intersection with P_u, @Recall magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MVos6sh2wha"
   },
   "outputs": [],
   "source": [
    "Recall_150 = {}\n",
    "for user in range(n_users):\n",
    "  indicies_movies = torch.where(A_test[user] == 1)[0]\n",
    "  real_Ru = set()\n",
    "  real_Pu = set()\n",
    "  if len(indicies_movies) == 0:\n",
    "    Recall_150[user+1] = (None, None)\n",
    "  else:\n",
    "\n",
    "    for elem in indicies_movies:\n",
    "      real_Pu.add(map_idx_movie[elem.item()])\n",
    "    \n",
    "    for elem in all_recall[user]:\n",
    "      real_Ru.add(map_idx_movie[elem.item()])\n",
    "\n",
    "    Recall_150[map_idx_user[user]] = (real_Pu & real_Ru, len(real_Pu & real_Ru)/len(real_Pu))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFSEtdFxPRvn"
   },
   "source": [
    "#Part 2: Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH17q5FBO8Pw"
   },
   "source": [
    "A really important note for this part. All the data manipulation and adjacency matrix making has been done. So none of that is included here. The same variables and data is used from the previous part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btdT6g2gP0hk"
   },
   "source": [
    "New Embedding object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eR9sODDPRqj"
   },
   "source": [
    "Need to do this to reset the embedding object from the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHq1-zAiPvqb"
   },
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(n, d).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX53vlx5PaDx"
   },
   "source": [
    "## Random walk function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnPb5PlPPZVJ"
   },
   "source": [
    "This part is very hard to follow, I will explain it in the code as to what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY4zB5RTUydP"
   },
   "outputs": [],
   "source": [
    "def node2vec(starting_node,length, p, q, A):\n",
    "\n",
    "  path = [starting_node]\n",
    "\n",
    "  user = True\n",
    "  # Always start the walk on a user node\n",
    "\n",
    "  BFS_DFS = \"DFS\"\n",
    "  # Default to a DFS walk (this actually doesn't do anything, just need to initalize the variable)\n",
    "\n",
    "  while len(path) < length:\n",
    "    # Run while the path is less than the given length \n",
    "\n",
    "    current_node = path[-1]\n",
    "    # Take the last node in the path (the node being explored)\n",
    "\n",
    "    if user == True:\n",
    "      neighbours = np.where(A[current_node] == 1)\n",
    "    else:\n",
    "      neighbours = np.where(A[:,current_node] == 1)\n",
    "\n",
    "    # Depending on if the node is a user or movie we need to set its neighbours\n",
    "    # Users will never be neighbours to other users\n",
    "    # Movies will never be neighbouts to other movies\n",
    "\n",
    "    breaker = False\n",
    "    # Initalizing a breaker variable (to get out of the while loop)\n",
    "\n",
    "    while True:\n",
    "      if random.random() < 1/p:\n",
    "        BFS_DFS = \"BFS\"\n",
    "        break \n",
    "      for i in range(len(neighbours)):\n",
    "        if random.random() < 1/q:\n",
    "          BFS_DFS = \"DFS\"\n",
    "          breaker = True\n",
    "          break\n",
    "      if breaker:\n",
    "        break\n",
    "\n",
    "      # This while loop changes the value of BFS_DFS\n",
    "      # It sets which type of exploration needs to be done \n",
    "\n",
    "    if (len(path)) == 1:\n",
    "      if (len(neighbours[0])) == 0:\n",
    "        return None\n",
    "      else:\n",
    "        path.append(random.choice(neighbours[0]))\n",
    "\n",
    "    elif (len(path)) > 1:\n",
    "      if BFS_DFS == \"DFS\":\n",
    "        if len(neighbours[0]) == 0:\n",
    "          path.append(path[-2])\n",
    "        else:\n",
    "          path.append(random.choice(neighbours[0]))      \n",
    "      elif BFS_DFS == \"BFS\":\n",
    "        path.append(path[-2])\n",
    "\n",
    "    # This simply adds the correct node to the path\n",
    "    # If DFS add a random neighbour, if BFS go back to the original node\n",
    "    # If the node has no neighbours go ba\n",
    "    \n",
    "    user = not(user)\n",
    "    # Change the variable from user to movie or vise versa\n",
    "  return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Hier8_PhF1"
   },
   "source": [
    "## Cost of Random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_8ZYvBRjar"
   },
   "source": [
    "This is the cost function described in the handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9UKvFZPYWqV"
   },
   "outputs": [],
   "source": [
    "def cost_node2vec(n_users, n_movies, emb_users, emb_movies, p, q, walk_length):\n",
    "  walks = []\n",
    "  total = 0\n",
    "  for user in range(n_users):\n",
    "    walks.append(node2vec(user,walk_length, p, q, A))\n",
    "    if walks[-1] == None:\n",
    "      continue\n",
    "    neighbours_user = walks[user][::2]\n",
    "    neighbours_movie = walks[user][1::2]\n",
    "\n",
    "    neigh_user_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_users[neighbours_user],0,1)))))\n",
    "    neigh_movie_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_movies[neighbours_movie],0,1)))))\n",
    "\n",
    "    denominator = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_users,0,1))))) + torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_movies,0,1)))))\n",
    "\n",
    "    total += neigh_user_sum + neigh_movie_sum - denominator\n",
    "\n",
    "  return 1/total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77hdhgsOPlvf"
   },
   "source": [
    "## Update the Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqWIKPA6RvMj"
   },
   "source": [
    "Same update function as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRIEwzGglryq"
   },
   "outputs": [],
   "source": [
    "def update_node2vec(n_users, n_movies, embedding):  \n",
    "  emb_movies = embedding(torch.arange(n_movies).to(device))\n",
    "  emb_users = embedding(torch.arange(n_movies, n).to(device))\n",
    "\n",
    "  return emb_movies, emb_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7DNqzQpPoqj"
   },
   "source": [
    "## Train the Node2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llVm2lyZRz-g"
   },
   "source": [
    "The training model is similar to the previous one. The main difference here is cost function and the 3 new parameters being p,q and walk_length. These are hyper-parameters and dictate the random-walk from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0sdvoS1lAJh"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "embedding = torch.nn.Embedding(n_users+n_movies, d).to(device)\n",
    "optimizer = torch.optim.Adam([*embedding.parameters()], lr = 0.0001)\n",
    "\n",
    "p = 7\n",
    "q = 10\n",
    "walk_length  = 7\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    emb_movies, emb_users = update_node2vec(n_users, n_movies, embedding)\n",
    "    cost = cost_node2vec(n_users, n_movies, emb_users, emb_movies, p, q, walk_length)\n",
    "\n",
    "    optimizer.zero_grad()           # cleans the gradients\n",
    "    cost.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "  \n",
    "    if epoch % 50 == 0:\n",
    "      print(\"epoch = \", epoch, \"cost=\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-5GcQHwP9s7"
   },
   "source": [
    "## Implimenting @Recall150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-GV4c45Sjh9"
   },
   "source": [
    "Same implimentation as the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s09r2jNLQBiF"
   },
   "outputs": [],
   "source": [
    "Recall_150_n2v = {}\n",
    "for user in range(n_users):\n",
    "  indicies_movies = torch.where(A_test[user] == 1)[0]\n",
    "  real_Ru = set()\n",
    "  real_Pu = set()\n",
    "  if len(indicies_movies) == 0:\n",
    "    Recall_150_n2v[user+1] = (None, None)\n",
    "  else:\n",
    "\n",
    "    for elem in indicies_movies:\n",
    "      real_Pu.add(map_idx_movie[elem.item()])\n",
    "    \n",
    "    for elem in all_recall[user]:\n",
    "      real_Ru.add(map_idx_movie[elem.item()])\n",
    "\n",
    "\n",
    "    Recall_150_n2v[map_idx_user[user]] = (real_Pu & real_Ru, len(real_Pu & real_Ru)/len(real_Pu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hq2SZl844ShT"
   },
   "outputs": [],
   "source": [
    "Recall_150_n2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_JIBB5RSnUd"
   },
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjvI4PK9SpqB"
   },
   "source": [
    "So the lab did not go entirely as planned. The results from Part 1 and Part 2 of the lab did not fair well. Most of the code I thought would work properly, hwoever there are most likely some tweaks that causes the Recall150 to not produce the correct results. I do believe with more guidance as to how to impliment certain parts of the code would be beneficial for sure. I did do the best I can with the given time and knowledge of this course."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
