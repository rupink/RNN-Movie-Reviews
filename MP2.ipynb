{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5MNsWoMEV_o"
   },
   "source": [
    "MP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceohaL_jEi4B"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FwPk8xvSK8gq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YCiAM6QEh36"
   },
   "source": [
    "# Loading and splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKxl0ikhE0mQ"
   },
   "source": [
    "We use a 80/20 split for the training and testing data which can be seen by the choices of the slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lrg6ol3_LKI_"
   },
   "outputs": [],
   "source": [
    "  ratings = pd.read_csv(\"http://www.cs.toronto.edu/~guerzhoy/324/movielens/ratings.csv\")\n",
    "  ratings_train = ratings.sort_values(by=['timestamp'])[0:80668]\n",
    "  ratings_test = ratings.sort_values(by=['timestamp'])[80668:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "h1F4_cAkFDXQ",
    "outputId": "ce062974-8eed-48a3-f724-ea0fdd4c3bf9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66719</th>\n",
       "      <td>429</td>\n",
       "      <td>595</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66716</th>\n",
       "      <td>429</td>\n",
       "      <td>588</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66717</th>\n",
       "      <td>429</td>\n",
       "      <td>590</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66718</th>\n",
       "      <td>429</td>\n",
       "      <td>592</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66712</th>\n",
       "      <td>429</td>\n",
       "      <td>432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79752</th>\n",
       "      <td>495</td>\n",
       "      <td>132796</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1458634739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79756</th>\n",
       "      <td>495</td>\n",
       "      <td>139385</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1458634761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79747</th>\n",
       "      <td>495</td>\n",
       "      <td>122882</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1458634764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79566</th>\n",
       "      <td>495</td>\n",
       "      <td>2959</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1458634866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79724</th>\n",
       "      <td>495</td>\n",
       "      <td>99114</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1458635162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80668 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "66719     429      595     5.0   828124615\n",
       "66716     429      588     5.0   828124615\n",
       "66717     429      590     5.0   828124615\n",
       "66718     429      592     5.0   828124615\n",
       "66712     429      432     3.0   828124615\n",
       "...       ...      ...     ...         ...\n",
       "79752     495   132796     1.0  1458634739\n",
       "79756     495   139385     5.0  1458634761\n",
       "79747     495   122882     4.5  1458634764\n",
       "79566     495     2959     5.0  1458634866\n",
       "79724     495    99114     5.0  1458635162\n",
       "\n",
       "[80668 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfUIBUOiFK8b"
   },
   "source": [
    "# Part 1: Training with **Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94KtfZfhKtwv"
   },
   "source": [
    "We choose to go for one embedding object here for users and movies instead of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ja8ac4w6L0Cg"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8560\\3442697579.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cuda'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    221\u001b[0m                 \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                     \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    194\u001b[0m             raise RuntimeError(\n\u001b[0;32m    195\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "n_users = len(ratings_train.userId.unique())\n",
    "n_movies = len(ratings_train.movieId.unique())\n",
    "n = n_users + n_movies\n",
    "d = 10\n",
    "device = 'cuda'\n",
    "embedding = torch.nn.Embedding(n, d).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icevuLRHFfrP"
   },
   "source": [
    "## Mapping the Movies and Users to Indicies forward and backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULnlW5kKK4zD"
   },
   "source": [
    "Here we want to access the movies and users as indicies, but then also access the incidices to get the movies and users. This will become very useful for training the data, and also very useful for getting the correct userIDs and movieIDs at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7oBA8hoyd3_-"
   },
   "outputs": [],
   "source": [
    "map_movies = {}\n",
    "map_users = {}\n",
    "map_idx_user = {}\n",
    "map_idx_movie = {}\n",
    "\n",
    "i = 0\n",
    "for index in ratings_train.index:\n",
    "  if ratings_train[\"movieId\"][index] not in map_movies:\n",
    "    map_movies[ratings_train[\"movieId\"][index]] = i\n",
    "    map_idx_movie[i] = ratings_train[\"movieId\"][index]\n",
    "    i+=1\n",
    "\n",
    "i = 0\n",
    "for index in ratings_train.index:\n",
    "  if ratings_train[\"userId\"][index] not in map_users:\n",
    "    map_users[ratings_train[\"userId\"][index]] = i\n",
    "    map_idx_user[i] = ratings_train[\"userId\"][index]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuHCHpbsFv1t"
   },
   "source": [
    "## Creating the Adjacency Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz89ZbzjLKL1"
   },
   "source": [
    "The adjacency matrix represents where the user rated a movie 5 star as 1, has seen the movie but not rated it 5 star as -1, and not seen as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wAqS3tAq-a1z"
   },
   "outputs": [],
   "source": [
    "A = torch.zeros((n_users, n_movies))\n",
    "for index in ratings_train.index:\n",
    "  if ratings_train[\"rating\"][index] == 5.0:\n",
    "    A[map_users[ratings_train[\"userId\"][index]]][map_movies[ratings_train[\"movieId\"][index]]] = 1\n",
    "  else:\n",
    "    A[map_users[ratings_train[\"userId\"][index]]][map_movies[ratings_train[\"movieId\"][index]]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvAg7uzDF_ov",
    "outputId": "e49ef5f5-3824-48eb-e314-3c75e230892c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  1.,  1.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0., -1.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ..., -1., -1.,  1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRYnXA91GCn8"
   },
   "source": [
    "## Creating the Embeddings for the Movies and Users as an update function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNZEzKQrLX5H"
   },
   "source": [
    "Every time the training loop runs, the new embeddings of the users and movies need to be updated. This function will do that in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J5M2EqHttRRi"
   },
   "outputs": [],
   "source": [
    "def update(n_users, n_movies, embedding):\n",
    "  emb_movies = embedding(torch.arange(n_movies))\n",
    "\n",
    "  emb_users = embedding(torch.arange(n_movies, n))\n",
    "\n",
    "  return emb_users, emb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYlYoWv1GMTo"
   },
   "source": [
    "## The Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJFAmiTFL15N"
   },
   "source": [
    "The cost function is as described in the lab handout. The difference here is that it returns 1/total, since we need to optimize the function given in the handout, we try to reduce 1/total as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1qTXut-Dy55E"
   },
   "outputs": [],
   "source": [
    "def cost(n_users, n_movies, emb_users, emb_movies, A):\n",
    "    total = 0 \n",
    "    for i in range(len(A)):\n",
    "      movies_5star = np.where(A[i] == 1)[0]\n",
    "      movies_4star = np.where(A[i] != 1)[0]\n",
    "\n",
    "      five_star_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[i],torch.transpose(emb_movies[movies_5star], 0, 1))))) * 200\n",
    "      four_star_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[i],torch.transpose(emb_movies[movies_4star], 0, 1)))))\n",
    "\n",
    "      total+= (five_star_sum - four_star_sum)\n",
    "\n",
    "    \n",
    "    return 1/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zKwPnTGIOwB"
   },
   "source": [
    "## Training the Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3Wt7MiLME9X"
   },
   "source": [
    "The training loop takes 1000 epochs, a learning rate of 0.0001, and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LJThbEp_Qre1",
    "outputId": "149b4efa-35e9-4fea-95ad-72c0a355504b"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 10: ldb should be at least max(1, 0), but have 0 at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-6nmox5re\\aten\\src\\TH/generic/THBlas.cpp:368",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8560\\3610245927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m           \u001b[1;31m# cleans the gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 10: ldb should be at least max(1, 0), but have 0 at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-6nmox5re\\aten\\src\\TH/generic/THBlas.cpp:368"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 0.0001\n",
    "\n",
    "params = [*embedding.parameters()] \n",
    "optimizer = torch.optim.Adam(params, lr = lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    emb_users, emb_movies = update(n_users, n_movies, embedding)\n",
    "    loss = cost(n_users, n_movies, emb_users, emb_movies, A)\n",
    "\n",
    "    optimizer.zero_grad()           # cleans the gradients\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "  \n",
    "    if epoch % 50 == 0:\n",
    "      print(\"epoch = \", epoch, \"loss=\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GZXsD6_IU3K"
   },
   "source": [
    "## Getting 150 highest dot products between movies and users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THu4hD5mIehX"
   },
   "source": [
    "Here we find the top150 movies per user. I do think this code is the hardest to follow along, so it is commented to explain each line, instead of an overview.\n",
    "\n",
    "Important to note the \"torch.where(A[users] == 0)\" which states that the dot products are occuring between users and movies that have NOT been seen already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "j4BQqnh4eTuf",
    "outputId": "a71a7ba3-6950-4c68-fb5a-fd5c2af3358d"
   },
   "outputs": [],
   "source": [
    "all_comb = torch.matmul(emb_users, torch.transpose(emb_movies, 0 , 1))\n",
    "# Multiplies the user and movies embeddings matricies together\n",
    "\n",
    "all_recall = []\n",
    "\n",
    "for users in range(n_users):\n",
    "  ind = torch.where(A[users] == 0)[0] \n",
    "  # Indicies for the movies that the user has not seen\n",
    "\n",
    "  user_mul_movie = all_comb[users, ind]\n",
    "  # Gets the dot product values of all the movies that have not been seen for the user \n",
    "\n",
    "  indicies_sorted = torch.argsort(user_mul_movie,-1,True)\n",
    "  # Sorts these dot products\n",
    "\n",
    "  if len(indicies_sorted) < 150:\n",
    "    take_top = len(indicies_sorted)\n",
    "  else:\n",
    "    take_top = 150\n",
    "  # These statements check if there are 150 reccomendations for the movies or less\n",
    "\n",
    "  sorted_movie_ids = ind[indicies_sorted]\n",
    "  top_150 = sorted_movie_ids[0:take_top]\n",
    "\n",
    "  all_recall.append(top_150)\n",
    "  # Puts the top movie reccomendations in a list where the indicies represent the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLc-_MI2_rEj"
   },
   "outputs": [],
   "source": [
    "all_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jMP6eVcI2GD"
   },
   "source": [
    "## Dropping Test set rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jIVPx96I5k_"
   },
   "source": [
    "All rows that are dropped are the ones where the user or movie do not occur in the training data. These cannot possibly be in the Recall150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY2KkwaJmu0A"
   },
   "outputs": [],
   "source": [
    "for index in ratings_test.index:\n",
    "  if (ratings_test[\"userId\"][index] not in map_users) or (ratings_test[\"movieId\"][index] not in map_movies):\n",
    "    ratings_test = ratings_test.drop(index = index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZo6MLKz0RjH"
   },
   "outputs": [],
   "source": [
    "ratings_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMInDyQXJHcz"
   },
   "source": [
    "## Creating a Test set adjacency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7boGehabOaw1"
   },
   "source": [
    "This creates the adjacency matrix for the test data. Same procedure as the training adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndYNZRnNpYTf"
   },
   "outputs": [],
   "source": [
    "A_test = torch.zeros((n_users, n_movies))\n",
    "for (i, index) in enumerate(ratings_test.index):\n",
    "  if ratings_test[\"rating\"][index] == 5:\n",
    "    A_test[map_users[ratings_test[\"userId\"][index]]][map_movies[ratings_test[\"movieId\"][index]]] = 1\n",
    "  else:\n",
    "    A_test[map_users[ratings_test[\"userId\"][index]]][map_movies[ratings_test[\"movieId\"][index]]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdFdcyIgAkMY"
   },
   "outputs": [],
   "source": [
    "A_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MFhShLeLJPqo"
   },
   "source": [
    "## Implimenting @Recall150 (Test Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCQAS0CvJTt9"
   },
   "source": [
    "The output is a dictionary containing the user as the key and a tuple (R_u intersection with P_u, @Recall magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MVos6sh2wha"
   },
   "outputs": [],
   "source": [
    "Recall_150 = {}\n",
    "for user in range(n_users):\n",
    "  indicies_movies = torch.where(A_test[user] == 1)[0]\n",
    "  real_Ru = set()\n",
    "  real_Pu = set()\n",
    "  if len(indicies_movies) == 0:\n",
    "    Recall_150[user+1] = (None, None)\n",
    "  else:\n",
    "\n",
    "    for elem in indicies_movies:\n",
    "      real_Pu.add(map_idx_movie[elem.item()])\n",
    "    \n",
    "    for elem in all_recall[user]:\n",
    "      real_Ru.add(map_idx_movie[elem.item()])\n",
    "\n",
    "    Recall_150[map_idx_user[user]] = (real_Pu & real_Ru, len(real_Pu & real_Ru)/len(real_Pu))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFSEtdFxPRvn"
   },
   "source": [
    "#Part 2: Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH17q5FBO8Pw"
   },
   "source": [
    "A really important note for this part. All the data manipulation and adjacency matrix making has been done. So none of that is included here. The same variables and data is used from the previous part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btdT6g2gP0hk"
   },
   "source": [
    "New Embedding object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eR9sODDPRqj"
   },
   "source": [
    "Need to do this to reset the embedding object from the previous part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHq1-zAiPvqb"
   },
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(n, d).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX53vlx5PaDx"
   },
   "source": [
    "## Random walk function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnPb5PlPPZVJ"
   },
   "source": [
    "This part is very hard to follow, I will explain it in the code as to what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY4zB5RTUydP"
   },
   "outputs": [],
   "source": [
    "def node2vec(starting_node,length, p, q, A):\n",
    "\n",
    "  path = [starting_node]\n",
    "\n",
    "  user = True\n",
    "  # Always start the walk on a user node\n",
    "\n",
    "  BFS_DFS = \"DFS\"\n",
    "  # Default to a DFS walk (this actually doesn't do anything, just need to initalize the variable)\n",
    "\n",
    "  while len(path) < length:\n",
    "    # Run while the path is less than the given length \n",
    "\n",
    "    current_node = path[-1]\n",
    "    # Take the last node in the path (the node being explored)\n",
    "\n",
    "    if user == True:\n",
    "      neighbours = np.where(A[current_node] == 1)\n",
    "    else:\n",
    "      neighbours = np.where(A[:,current_node] == 1)\n",
    "\n",
    "    # Depending on if the node is a user or movie we need to set its neighbours\n",
    "    # Users will never be neighbours to other users\n",
    "    # Movies will never be neighbouts to other movies\n",
    "\n",
    "    breaker = False\n",
    "    # Initalizing a breaker variable (to get out of the while loop)\n",
    "\n",
    "    while True:\n",
    "      if random.random() < 1/p:\n",
    "        BFS_DFS = \"BFS\"\n",
    "        break \n",
    "      for i in range(len(neighbours)):\n",
    "        if random.random() < 1/q:\n",
    "          BFS_DFS = \"DFS\"\n",
    "          breaker = True\n",
    "          break\n",
    "      if breaker:\n",
    "        break\n",
    "\n",
    "      # This while loop changes the value of BFS_DFS\n",
    "      # It sets which type of exploration needs to be done \n",
    "\n",
    "    if (len(path)) == 1:\n",
    "      if (len(neighbours[0])) == 0:\n",
    "        return None\n",
    "      else:\n",
    "        path.append(random.choice(neighbours[0]))\n",
    "\n",
    "    elif (len(path)) > 1:\n",
    "      if BFS_DFS == \"DFS\":\n",
    "        if len(neighbours[0]) == 0:\n",
    "          path.append(path[-2])\n",
    "        else:\n",
    "          path.append(random.choice(neighbours[0]))      \n",
    "      elif BFS_DFS == \"BFS\":\n",
    "        path.append(path[-2])\n",
    "\n",
    "    # This simply adds the correct node to the path\n",
    "    # If DFS add a random neighbour, if BFS go back to the original node\n",
    "    # If the node has no neighbours go ba\n",
    "    \n",
    "    user = not(user)\n",
    "    # Change the variable from user to movie or vise versa\n",
    "  return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Hier8_PhF1"
   },
   "source": [
    "## Cost of Random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_8ZYvBRjar"
   },
   "source": [
    "This is the cost function described in the handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R9UKvFZPYWqV"
   },
   "outputs": [],
   "source": [
    "def cost_node2vec(n_users, n_movies, emb_users, emb_movies, p, q, walk_length):\n",
    "  walks = []\n",
    "  total = 0\n",
    "  for user in range(n_users):\n",
    "    walks.append(node2vec(user,walk_length, p, q, A))\n",
    "    if walks[-1] == None:\n",
    "      continue\n",
    "    neighbours_user = walks[user][::2]\n",
    "    neighbours_movie = walks[user][1::2]\n",
    "\n",
    "    neigh_user_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_users[neighbours_user],0,1)))))\n",
    "    neigh_movie_sum = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_movies[neighbours_movie],0,1)))))\n",
    "\n",
    "    denominator = torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_users,0,1))))) + torch.sum(torch.log(torch.sigmoid(torch.matmul(emb_users[user], torch.transpose(emb_movies,0,1)))))\n",
    "\n",
    "    total += neigh_user_sum + neigh_movie_sum - denominator\n",
    "\n",
    "  return 1/total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77hdhgsOPlvf"
   },
   "source": [
    "## Update the Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eqWIKPA6RvMj"
   },
   "source": [
    "Same update function as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRIEwzGglryq"
   },
   "outputs": [],
   "source": [
    "def update_node2vec(n_users, n_movies, embedding):  \n",
    "  emb_movies = embedding(torch.arange(n_movies).to(device))\n",
    "  emb_users = embedding(torch.arange(n_movies, n).to(device))\n",
    "\n",
    "  return emb_movies, emb_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7DNqzQpPoqj"
   },
   "source": [
    "## Train the Node2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llVm2lyZRz-g"
   },
   "source": [
    "The training model is similar to the previous one. The main difference here is cost function and the 3 new parameters being p,q and walk_length. These are hyper-parameters and dictate the random-walk from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0sdvoS1lAJh"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "embedding = torch.nn.Embedding(n_users+n_movies, d).to(device)\n",
    "optimizer = torch.optim.Adam([*embedding.parameters()], lr = 0.0001)\n",
    "\n",
    "p = 7\n",
    "q = 10\n",
    "walk_length  = 7\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    emb_movies, emb_users = update_node2vec(n_users, n_movies, embedding)\n",
    "    cost = cost_node2vec(n_users, n_movies, emb_users, emb_movies, p, q, walk_length)\n",
    "\n",
    "    optimizer.zero_grad()           # cleans the gradients\n",
    "    cost.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "  \n",
    "    if epoch % 50 == 0:\n",
    "      print(\"epoch = \", epoch, \"cost=\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-5GcQHwP9s7"
   },
   "source": [
    "## Implimenting @Recall150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-GV4c45Sjh9"
   },
   "source": [
    "Same implimentation as the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s09r2jNLQBiF"
   },
   "outputs": [],
   "source": [
    "Recall_150_n2v = {}\n",
    "for user in range(n_users):\n",
    "  indicies_movies = torch.where(A_test[user] == 1)[0]\n",
    "  real_Ru = set()\n",
    "  real_Pu = set()\n",
    "  if len(indicies_movies) == 0:\n",
    "    Recall_150_n2v[user+1] = (None, None)\n",
    "  else:\n",
    "\n",
    "    for elem in indicies_movies:\n",
    "      real_Pu.add(map_idx_movie[elem.item()])\n",
    "    \n",
    "    for elem in all_recall[user]:\n",
    "      real_Ru.add(map_idx_movie[elem.item()])\n",
    "\n",
    "\n",
    "    Recall_150_n2v[map_idx_user[user]] = (real_Pu & real_Ru, len(real_Pu & real_Ru)/len(real_Pu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hq2SZl844ShT"
   },
   "outputs": [],
   "source": [
    "Recall_150_n2v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_JIBB5RSnUd"
   },
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjvI4PK9SpqB"
   },
   "source": [
    "So the lab did not go entirely as planned. The results from Part 1 and Part 2 of the lab did not fair well. Most of the code I thought would work properly, hwoever there are most likely some tweaks that causes the Recall150 to not produce the correct results. I do believe with more guidance as to how to impliment certain parts of the code would be beneficial for sure. I did do the best I can with the given time and knowledge of this course."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
